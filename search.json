[
  {
    "objectID": "quick_tour_of_the_notebook.html",
    "href": "quick_tour_of_the_notebook.html",
    "title": "02. A Quick Tour of The Notebook",
    "section": "",
    "text": "If you‚Äôre reading this properly, then you‚Äôve installed Anaconda correctly. You are looking at a Jupyter notebook, which is a user-friendly combination of code and text that helps you perform data analysis and visualization easily!"
  },
  {
    "objectID": "quick_tour_of_the_notebook.html#introducing-the-notebook",
    "href": "quick_tour_of_the_notebook.html#introducing-the-notebook",
    "title": "02. A Quick Tour of The Notebook",
    "section": "Introducing The Notebook",
    "text": "Introducing The Notebook\nA Jupyter notebook consists of text and images. The text can be Markdown or code.\nYou can include images as a weblink:\n\n\n\nclaridge-chang-lab-logo\n\n\nIf you‚Äôre not connected to the internet, the image above won‚Äôt render.\n\nDouble-click on this chunk of text. You should enter ‚Äúedit mode‚Äù which allows you to change the text.\nHit Shift+Enter to render the change."
  },
  {
    "objectID": "quick_tour_of_the_notebook.html#running-cells",
    "href": "quick_tour_of_the_notebook.html#running-cells",
    "title": "02. A Quick Tour of The Notebook",
    "section": "Running Cells",
    "text": "Running Cells\nFirst, we need to explain how to run cells. Try to run the cell below!\nNotice how the cell bracket on the left first becomes an asterisk ‚Äú*‚Äù to indicate the cell is running.\nOnce the cell has completed running, the asterisk is replaced by a number (in this case, ‚Äú1‚Äù). This is a running count of the number of cells you have run in this notebook.\n\nimport pandas as pd # Don't worry about this line yet. We'll explain it later below!\n\n\nprint(\"Hi! This is a cell. Press the ‚ñ∂ button in the toolbar above to run it.\")\n\nHi! This is a cell. Press the ‚ñ∂ button in the toolbar above to run it.\n\n\nYou can also run a cell with Shift+Enter.\nOne of the most useful things about IPython notebook is its tab completion.\nTry this: remove the ‚Äú#‚Äù in the cell below (called uncommenting) and click just after read_csv( in the cell below and press Shift+Tab.\n\n#pd.read_csv(\n\nYou should see this: \n\nThis is the documentation for the function pd.read_csv(). You should be able to scroll within the box.\nYou can also perform tab completion for function names.\nAfter removing the #, just after pd.r in the cell below and press Tab.\n\n#pd.r\n\nYou should see this:\n\n\n\nUsing Tab completion"
  },
  {
    "objectID": "quick_tour_of_the_notebook.html#saving-your-work",
    "href": "quick_tour_of_the_notebook.html#saving-your-work",
    "title": "02. A Quick Tour of The Notebook",
    "section": "Saving Your Work",
    "text": "Saving Your Work\nAs of the latest stable version, JupyterLab will autosave your notebook! But you should always click the üíæ button or hit Ctrl+S regularly."
  },
  {
    "objectID": "quick_tour_of_the_notebook.html#introducing-python",
    "href": "quick_tour_of_the_notebook.html#introducing-python",
    "title": "02. A Quick Tour of The Notebook",
    "section": "Introducing Python",
    "text": "Introducing Python\n\n# This is a code cell. You can change the cell type in the dropdown menu above.\n# In Python, anything following a `#` is a comment; it is ignored. \n# Below, we demonstrate a simple addition of two variables.\n\na = 5\nb = 6\nprint(a + b)\nprint(a * b)\n\n11\n30\n\n\nTry changing the values of a and b, and hit Shift+Enter or the Play button ‚ñ∂ above.\nCheck to see if the values of a + b and a * b are as expected.\nCongratulations! üéâ üéä\nYou are now officially a programmer!!!"
  },
  {
    "objectID": "quick_tour_of_the_notebook.html#for-loops",
    "href": "quick_tour_of_the_notebook.html#for-loops",
    "title": "02. A Quick Tour of The Notebook",
    "section": "FOR loops",
    "text": "FOR loops\nOne of the key advantages of coding is the ability to automate repetitive processes with loops.\n\nfor i in range(10):\n    print(i, i*2, i*3)\n\n0 0 0\n1 2 3\n2 4 6\n3 6 9\n4 8 12\n5 10 15\n6 12 18\n7 14 21\n8 16 24\n9 18 27"
  },
  {
    "objectID": "quick_tour_of_the_notebook.html#quick-introduction-to-arrays",
    "href": "quick_tour_of_the_notebook.html#quick-introduction-to-arrays",
    "title": "02. A Quick Tour of The Notebook",
    "section": "Quick Introduction to Arrays",
    "text": "Quick Introduction to Arrays\nPython has several different types of data structures. An important data structure is the list.\n\nmy_list = [1, 2, 3, 4, \"John\", \"Mary\", 1984]\n\nYou can access items of this list with using a 0-indexed notation. That is, the first item has an index of 0.\n\nmy_list[0]\n\n1\n\n\n\nmy_list[1]\n\n2\n\n\nPython allows negative-numerical indexing, which accesses the list in reverse.\n\nmy_list[-1]\n\n1984\n\n\n\nmy_list[-2]\n\n'Mary'\n\n\nYou can append items to the list.\n\nmy_list.append(\"new item\")\n\nmy_list\n\n[1, 2, 3, 4, 'John', 'Mary', 1984, 'new item']\n\n\nYou can also remove items from the list.\n\nmy_list.remove(4)\n\nmy_list.remove(\"John\")\n\nmy_list\n\n[1, 2, 3, 'Mary', 1984, 'new item']\n\n\nYou can also combine lists.\n\n[1, 2, 3] + [\"Four\", \"cinco\", \"ÂÖ≠\"]\n\n[1, 2, 3, 'Four', 'cinco', 'ÂÖ≠']"
  },
  {
    "objectID": "quick_tour_of_the_notebook.html#quick-introduction-to-dictionaries",
    "href": "quick_tour_of_the_notebook.html#quick-introduction-to-dictionaries",
    "title": "02. A Quick Tour of The Notebook",
    "section": "Quick Introduction to Dictionaries",
    "text": "Quick Introduction to Dictionaries\nAnother important data structure is the dictionary. It is often referred to as a dict. As the name suggests, you can look up values with keywords.\n\nmy_dict = {\"John\": 99,\n           \"Mary\": 100,\n           \"Address\": \"8 College Road, S(169857)\",\n           \"Fragments\": [\"attagagacca\", \"ggctttcta\", \"ttctcaatggt\"]}\n\n\nmy_dict[\"John\"]\n\n99\n\n\n\nmy_dict[\"Address\"]\n\n'8 College Road, S(169857)'\n\n\n\nmy_dict[\"Fragments\"]\n\n['attagagacca', 'ggctttcta', 'ttctcaatggt']\n\n\nYou can add values to a list by assigning it to a keyword.\n\nmy_dict[\"Susan\"] = 1000\n\nmy_dict\n\n{'John': 99,\n 'Mary': 100,\n 'Address': '8 College Road, S(169857)',\n 'Fragments': ['attagagacca', 'ggctttcta', 'ttctcaatggt'],\n 'Susan': 1000}\n\n\nRemoving dictionary entries with the del command.\n\ndel my_dict[\"John\"]\n\nmy_dict\n\n{'Mary': 100,\n 'Address': '8 College Road, S(169857)',\n 'Fragments': ['attagagacca', 'ggctttcta', 'ttctcaatggt'],\n 'Susan': 1000}\n\n\n\nQuiz\nHow do I remove ‚Äòggctttcta‚Äô from my_dict[\"Fragments\"]?"
  },
  {
    "objectID": "quick_tour_of_the_notebook.html#importing-libraries",
    "href": "quick_tour_of_the_notebook.html#importing-libraries",
    "title": "02. A Quick Tour of The Notebook",
    "section": "Importing Libraries",
    "text": "Importing Libraries\nPython has a large selection of libraries for scientific computing and data visualization. These libraries have to be manually imported into your session.\n\nimport pandas as pd\n# This translates into English as 'Hey Python, load the library `pandas`, and call it `pd` for short!'\n\nimport matplotlib.pyplot as plt\n# In English: 'Python, there's a submodule `pyplot` in the library `matplotlib`. Import this submodule as `plt`.\n\nimport seaborn as sns\n# Now, can you translate this line of Python into English?\n\n## For some reason, this gave an error in nbdev_test\n# %matplotlib inline\n## This is known as a \"IPython magic command\". Some magic commands control how the notebook behaves. \n## This particular line tells the notebook to render any output by `matplotlib` as an inline image."
  },
  {
    "objectID": "quick_tour_of_the_notebook.html#further-reading",
    "href": "quick_tour_of_the_notebook.html#further-reading",
    "title": "02. A Quick Tour of The Notebook",
    "section": "Further Reading",
    "text": "Further Reading\nRead more about the JupyterLab interface.\nJupyter follows in the tradition of literate programming, the idea that code should be a piece of literature that incorporates prose, images, and code all in a single document.\nMore about magic commands in Jupyter.\nWhy is this named ‚ÄúJupyter‚Äù? From this link:\n\nThe name has its origins in a few different places. First, the names comes from the planet Jupiter. We wanted to pick a name that evoked the traditions and ideas of science. Second, the core programming languages supported by Jupyter are Julia, Python and R. While the name Jupyter is not a direct acronym for these languages, it nods its head in those directions. In particular, the ‚Äúy‚Äù in the middle of Jupyter was chosen to honor our Python heritage. Third, Galileo was the first person to discover the moons of Jupiter. His publication on the moons of Jupiter is an early example of research that includes the underlying data in the publication. This is one of the core ideas and requirements for scientific reproducibility. Reproducibility is one of the main focuses of our project."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modern Data Analysis",
    "section": "",
    "text": "By Joses Ho, Sangyu Xu, and Adam Claridge-Chang\nPart of GMS6812 2022: Foundations of Precision Medicine hands-on workshops (PhD programme in Clinical and Translational Sciences)\n\n9 am - 1 pm, Febuary 14, 2023\nDuke-NUS Medical School\nThe goal of this class is to introduce biomedical scientists to data analysis with Python notebooks. There are two parts to the session: a lecture on the key issues in data analysis and a hands-on tutorial. Please do the following preparations before class.\n\nRead the Introduction and install the prerequisite software on your laptop.\nGo through a Quick Tour of the Notebook to familiarise yoruself to the jupyter notebook environment.\nBring your laptop to class, and we will go through the examples in Data Analysis with Jupyter.\n\nIf we have more time in class, you will also be introduced to our estimation statistics package DABEST Introduction."
  },
  {
    "objectID": "data_analysis_with_jupyter_and_python.html",
    "href": "data_analysis_with_jupyter_and_python.html",
    "title": "03. Data Analysis with Jupyter and Python",
    "section": "",
    "text": "import seaborn as sns\nimport pandas as pd\nimport numpy as np\n\nYou can already interact with the data files in your file directory with using the pandas.read_csv function:\n\nexploration_times = pd.read_csv(\"exploration_times.csv\") # have pandas read the csv file \"exploration_times.csv\" and store the data into the variable 'exploration_times'\n\n\nexploration_times # display the data\n\n\n\n\n\n  \n    \n      \n      WT\n      CCR5 KO\n    \n  \n  \n    \n      0\n      3.478549\n      4.983642\n    \n    \n      1\n      2.234100\n      3.502187\n    \n    \n      2\n      1.724468\n      2.469726\n    \n    \n      3\n      1.723056\n      2.210396\n    \n    \n      4\n      0.965881\n      2.508039\n    \n    \n      5\n      0.726249\n      1.465072\n    \n    \n      6\n      0.490557\n      1.202951\n    \n    \n      7\n      0.217963\n      1.474133\n    \n    \n      8\n      0.479953\n      0.976419\n    \n    \n      9\n      -0.053350\n      0.752514\n    \n    \n      10\n      0.505003\n      0.742008\n    \n    \n      11\n      0.256178\n      1.004063"
  },
  {
    "objectID": "data_analysis_with_jupyter_and_python.html#loading-data",
    "href": "data_analysis_with_jupyter_and_python.html#loading-data",
    "title": "03. Data Analysis with Jupyter and Python",
    "section": "Loading data",
    "text": "Loading data\nLet‚Äôs load in an example dataset. We shall load the iris flower dataset.\n\nThe Iris flower data set or Fisher‚Äôs Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in 1936. It is sometimes called Anderson‚Äôs Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species. Two of the three species were collected in the Gasp√© Peninsula ‚Äúall from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus‚Äù.\n\n\n\n\n\nThe data set consists of 50 samples from each of three species of Iris (iris setosa, iris virginica and iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n\n\n\n\nAn iris versicolor. (Photo by Danielle Langlois. Marking by Vijay Kotu and Bala Deshpande. Licensed under Creative Commons)\n\n\n\n\n\nAn iris setosa. (Photo by –î–µ–Ω–∏—Å –ê–Ω–∏—Å–∏–º–æ–≤. Public Domain)\n\n\n\n\n\nAn iris virginica. (Photo by Eric Hunt. Licensed under Creative Commons)\n\n\n\n# Read iris data from the sheet with pandas\niris = pd.read_csv(\"https://www.bitly.com/dukenusda\")\n\n## Or, since we have a copy of the file in the downloaded directory:\n# iris = pd.read_csv('iris.csv')\n\nYou have created a new object known as a pandas DataFrame, with the contents of the CSV. Think of it as a spreadsheet, but with a lot more useful features for data analysis. It has several methods we can use to handle, analyse, and plot the data.\nWe can peak at the data using the .head() method.\n\niris.head() # Gives us the first 5 rows of the dataframe.\n# iris.head(10) # Gives us the first 5 rows of the dataframe.\n\n\n\n\n\n  \n    \n      \n      sepal_length\n      sepal_width\n      petal_length\n      petal_width\n      species\n    \n  \n  \n    \n      0\n      5.1\n      3.5\n      1.4\n      0.2\n      setosa\n    \n    \n      1\n      4.9\n      3.0\n      1.4\n      0.2\n      setosa\n    \n    \n      2\n      4.7\n      3.2\n      1.3\n      0.2\n      setosa\n    \n    \n      3\n      4.6\n      3.1\n      1.5\n      0.2\n      setosa\n    \n    \n      4\n      5.0\n      3.6\n      1.4\n      0.2\n      setosa\n    \n  \n\n\n\n\nGet a summary of the data.\n\niris.describe()\n\n\n\n\n\n  \n    \n      \n      sepal_length\n      sepal_width\n      petal_length\n      petal_width\n    \n  \n  \n    \n      count\n      150.000000\n      150.000000\n      150.000000\n      150.000000\n    \n    \n      mean\n      5.843333\n      3.057333\n      3.758000\n      1.199333\n    \n    \n      std\n      0.828066\n      0.435866\n      1.765298\n      0.762238\n    \n    \n      min\n      4.300000\n      2.000000\n      1.000000\n      0.100000\n    \n    \n      25%\n      5.100000\n      2.800000\n      1.600000\n      0.300000\n    \n    \n      50%\n      5.800000\n      3.000000\n      4.350000\n      1.300000\n    \n    \n      75%\n      6.400000\n      3.300000\n      5.100000\n      1.800000\n    \n    \n      max\n      7.900000\n      4.400000\n      6.900000\n      2.500000\n    \n  \n\n\n\n\nLet‚Äôs see what is in the species column.\n\niris.species.unique()\n\narray(['setosa', 'versicolor', 'virginica'], dtype=object)"
  },
  {
    "objectID": "data_analysis_with_jupyter_and_python.html#plot-the-old-fashioned-bar-chart",
    "href": "data_analysis_with_jupyter_and_python.html#plot-the-old-fashioned-bar-chart",
    "title": "03. Data Analysis with Jupyter and Python",
    "section": "Plot the old-fashioned bar chart",
    "text": "Plot the old-fashioned bar chart\n\niris.head()\n\n\n\n\n\n  \n    \n      \n      sepal_length\n      sepal_width\n      petal_length\n      petal_width\n      species\n    \n  \n  \n    \n      0\n      5.1\n      3.5\n      1.4\n      0.2\n      setosa\n    \n    \n      1\n      4.9\n      3.0\n      1.4\n      0.2\n      setosa\n    \n    \n      2\n      4.7\n      3.2\n      1.3\n      0.2\n      setosa\n    \n    \n      3\n      4.6\n      3.1\n      1.5\n      0.2\n      setosa\n    \n    \n      4\n      5.0\n      3.6\n      1.4\n      0.2\n      setosa\n    \n  \n\n\n\n\n\nax1 = sns.barplot(data = iris, \n                  x = 'species', \n                  y = 'petal_width')\n\n# Axes should always be labelled.\n# ax1.set(xlabel='Species', ylabel='Mean Sepal length (cm)')"
  },
  {
    "objectID": "data_analysis_with_jupyter_and_python.html#plot-a-swarmplot-which-shows-all-the-data",
    "href": "data_analysis_with_jupyter_and_python.html#plot-a-swarmplot-which-shows-all-the-data",
    "title": "03. Data Analysis with Jupyter and Python",
    "section": "Plot a swarmplot, which shows all the data",
    "text": "Plot a swarmplot, which shows all the data\n\nax2 = sns.swarmplot(data = iris, \n                    x = 'species', \n                    y = 'petal_length',\n                   hue = 'species')\n\n# ax2.set(xlabel='Species', ylabel='Petal length (cm)')\n\nC:\\Users\\xusy\\.conda\\envs\\nbdevdabestdev\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 14.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)"
  },
  {
    "objectID": "data_analysis_with_jupyter_and_python.html#the-split-apply-combine-workflow",
    "href": "data_analysis_with_jupyter_and_python.html#the-split-apply-combine-workflow",
    "title": "03. Data Analysis with Jupyter and Python",
    "section": "The split-apply-combine workflow",
    "text": "The split-apply-combine workflow\nAll your scientific experiments follow a very simple analysis workflow: split-apply-combine\nYou do an experiment on 2 or more groups, apply some summary function to each group, and then aggregate the results.\n\n\n\n\niris.head()\n\n\n\n\n\n  \n    \n      \n      sepal_length\n      sepal_width\n      petal_length\n      petal_width\n      species\n    \n  \n  \n    \n      0\n      5.1\n      3.5\n      1.4\n      0.2\n      setosa\n    \n    \n      1\n      4.9\n      3.0\n      1.4\n      0.2\n      setosa\n    \n    \n      2\n      4.7\n      3.2\n      1.3\n      0.2\n      setosa\n    \n    \n      3\n      4.6\n      3.1\n      1.5\n      0.2\n      setosa\n    \n    \n      4\n      5.0\n      3.6\n      1.4\n      0.2\n      setosa\n    \n  \n\n\n\n\n\niris.groupby('species').mean()\n\n\n\n\n\n  \n    \n      \n      sepal_length\n      sepal_width\n      petal_length\n      petal_width\n    \n    \n      species\n      \n      \n      \n      \n    \n  \n  \n    \n      setosa\n      5.006\n      3.428\n      1.462\n      0.246\n    \n    \n      versicolor\n      5.936\n      2.770\n      4.260\n      1.326\n    \n    \n      virginica\n      6.588\n      2.974\n      5.552\n      2.026\n    \n  \n\n\n\n\n\niris.groupby('species').sem()\n\n\n\n\n\n  \n    \n      \n      sepal_length\n      sepal_width\n      petal_length\n      petal_width\n    \n    \n      species\n      \n      \n      \n      \n    \n  \n  \n    \n      setosa\n      0.049850\n      0.053608\n      0.024560\n      0.014904\n    \n    \n      versicolor\n      0.072998\n      0.044378\n      0.066455\n      0.027966\n    \n    \n      virginica\n      0.089927\n      0.045608\n      0.078050\n      0.038841\n    \n  \n\n\n\n\nThe plotting package seaborn does this automatically for you.\n\n# `catplot` is short for \"categorical plot\", \n# where either the x-axis or y-axis consists of categories.\n\nax3 = sns.catplot(data=iris, \n            kind='bar',   # there are several types of plots.\n#             errorbar='sd',      # plot the error bars as ¬± standard deviation, use this line if you have seaborn 0.12.x\n#             ci='sd',      # plot the error bars as ¬± standard deviations, use this line if you have seaborn 0.11.x.\n            col='species' # plot each species as its own column.\n           )\nax3.set_axis_labels(\"\", \"Length (cm)\")\n\n<seaborn.axisgrid.FacetGrid>\n\n\n\n\n\nYou should quickly notice that the plot isn‚Äôt as informative as we want it to be.\nThe current plot only allows us to investigate the relationships the four metrics within species.\nIdeally, we want to directly compare metrics between species.\nTo do so, we need to reshape the data."
  },
  {
    "objectID": "data_analysis_with_jupyter_and_python.html#the-long-form-vs-the-wide-form-of-your-data",
    "href": "data_analysis_with_jupyter_and_python.html#the-long-form-vs-the-wide-form-of-your-data",
    "title": "03. Data Analysis with Jupyter and Python",
    "section": "The Long-form vs the Wide-form of your data",
    "text": "The Long-form vs the Wide-form of your data\nOur iris dataframe is in the wide-form (below right) and we want to turn it into the long-form. In the original iris dataframe, the data is organised by unit (flower, in rows) and the columns contain a mixtrue of variables (sepal length, sepal width etc). In a long-form dataframe, each columne is a variable, and each row is an observation. (Please read Hadley Wickham‚Äôs https://vita.had.co.nz/papers/tidy-data.pdf to learn more about tidiness of datasets.)\n\n\n\nMichael Waskom, Seaborn Tutorial 2022\n\n\n\niris_tidy = pd.melt(iris.reset_index(), \n                    id_vars=['index','species'], \n                    var_name='metric', \n                    value_name='cm')\niris_tidy = iris_tidy.rename(columns = {'index': 'ID'})\n\n\niris\n\n\n\n\n\n  \n    \n      \n      sepal_length\n      sepal_width\n      petal_length\n      petal_width\n      species\n    \n  \n  \n    \n      0\n      5.1\n      3.5\n      1.4\n      0.2\n      setosa\n    \n    \n      1\n      4.9\n      3.0\n      1.4\n      0.2\n      setosa\n    \n    \n      2\n      4.7\n      3.2\n      1.3\n      0.2\n      setosa\n    \n    \n      3\n      4.6\n      3.1\n      1.5\n      0.2\n      setosa\n    \n    \n      4\n      5.0\n      3.6\n      1.4\n      0.2\n      setosa\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      145\n      6.7\n      3.0\n      5.2\n      2.3\n      virginica\n    \n    \n      146\n      6.3\n      2.5\n      5.0\n      1.9\n      virginica\n    \n    \n      147\n      6.5\n      3.0\n      5.2\n      2.0\n      virginica\n    \n    \n      148\n      6.2\n      3.4\n      5.4\n      2.3\n      virginica\n    \n    \n      149\n      5.9\n      3.0\n      5.1\n      1.8\n      virginica\n    \n  \n\n150 rows √ó 5 columns\n\n\n\n\niris_tidy\n\n\n\n\n\n  \n    \n      \n      ID\n      species\n      metric\n      cm\n    \n  \n  \n    \n      0\n      0\n      setosa\n      sepal_length\n      5.1\n    \n    \n      1\n      1\n      setosa\n      sepal_length\n      4.9\n    \n    \n      2\n      2\n      setosa\n      sepal_length\n      4.7\n    \n    \n      3\n      3\n      setosa\n      sepal_length\n      4.6\n    \n    \n      4\n      4\n      setosa\n      sepal_length\n      5.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      595\n      145\n      virginica\n      petal_width\n      2.3\n    \n    \n      596\n      146\n      virginica\n      petal_width\n      1.9\n    \n    \n      597\n      147\n      virginica\n      petal_width\n      2.0\n    \n    \n      598\n      148\n      virginica\n      petal_width\n      2.3\n    \n    \n      599\n      149\n      virginica\n      petal_width\n      1.8\n    \n  \n\n600 rows √ó 4 columns\n\n\n\n\nax4 = sns.catplot(data=iris_tidy, \n            x='metric', \n            y='cm', \n            hue='species',\n            kind='bar', \n            ci='sd',\n            aspect=1.5\n           )\n\n\n\n\n\n# f, ax = plt.subplots(1, figsize=(3,3))\n\nax5 = sns.catplot(data=iris_tidy, \n            kind='swarm', \n             x='species', y='cm', hue='metric',\n            size=4.5,\n            aspect=1.5,\n#             errorbar='sd',      # plot the error bars as ¬± standard deviation, use this line if you have seaborn 0.12.x\n#             ci='sd',      # plot the error bars as ¬± standard deviations, use this line if you have seaborn 0.11.x.\n            palette=['red','grey','orange','pink'],\n            \n           )\n\nC:\\Users\\xusy\\.conda\\envs\\nbdevdabestdev\\lib\\site-packages\\seaborn\\categorical.py:3750: UserWarning: The `size` parameter has been renamed to `height`; please update your code.\n  warnings.warn(msg, UserWarning)\nC:\\Users\\xusy\\.conda\\envs\\nbdevdabestdev\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 8.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)"
  },
  {
    "objectID": "data_analysis_with_jupyter_and_python.html#scatterplot-and-linear-regression-line",
    "href": "data_analysis_with_jupyter_and_python.html#scatterplot-and-linear-regression-line",
    "title": "03. Data Analysis with Jupyter and Python",
    "section": "Scatterplot and linear regression line",
    "text": "Scatterplot and linear regression line\nNext to the categorical plot, the scatter plot is a very useful visualization tool for biological experiments. Often we want to know how one variable is correlated with another, we can then use a scatterplot to easily take a quick look.\n\n# Draw a scatteplot of petal width versus length with a simple linear regression line\nax6 = sns.regplot(data=iris, \n                  ci=95,\n                  x=\"sepal_width\", \n                  y=\"petal_length\")\n\n\n# ax6.set(xlabel='Sepal width (cm)', ylabel='Sepal length (cm)')\n\n\n\n\n\nfor s in iris.species.unique():\n    ax7 = sns.regplot(data=iris.loc[iris.species == s], \n                  ci=95,\n                  x=\"sepal_width\", \n                  y=\"petal_length\", label = s)\n    ax7.legend()"
  },
  {
    "objectID": "data_analysis_with_jupyter_and_python.html#seaborn-allows-you-to-do-that-more-systematically-with-pairplot",
    "href": "data_analysis_with_jupyter_and_python.html#seaborn-allows-you-to-do-that-more-systematically-with-pairplot",
    "title": "03. Data Analysis with Jupyter and Python",
    "section": "Seaborn allows you to do that more systematically with pairplot",
    "text": "Seaborn allows you to do that more systematically with pairplot\nThis is like doing a scatter plot for each pair of the variables in one go. On the diagonal, distributions of values within each species group are plotted for each variable.\n\nfig = sns.pairplot(iris, hue=\"species\")"
  },
  {
    "objectID": "data_analysis_with_jupyter_and_python.html#dimension-reduction-with-principle-component-analysis",
    "href": "data_analysis_with_jupyter_and_python.html#dimension-reduction-with-principle-component-analysis",
    "title": "03. Data Analysis with Jupyter and Python",
    "section": "Dimension Reduction with Principle Component Analysis",
    "text": "Dimension Reduction with Principle Component Analysis\nWe have 4 dimensions we measured the irises on, what if we want a more concise way of describing the data? We can try to find 2 dimensions along which the data has the most variance.\n\nfrom sklearn import decomposition\nfrom sklearn import datasets\n\nimport matplotlib.pyplot as plt\n\niris_pca = datasets.load_iris()\nX = iris_pca.data\ny = iris_pca.target\n\npca = decomposition.PCA(n_components=2)\npca.fit(X)\nX = pca.transform(X)\n\n\nf, ax8 = plt.subplots(1, figsize = (5, 5))\nsns.scatterplot(x=X[:, 0], y=X[:, 1], hue=[iris_pca.target_names[i] for i in y], alpha = 0.7)\nax8.set_xlabel('PC1')\nax8.set_ylabel('PC2')\n\nText(0, 0.5, 'PC2')"
  },
  {
    "objectID": "data_analysis_with_jupyter_and_python.html#towards-publication-ready-plots",
    "href": "data_analysis_with_jupyter_and_python.html#towards-publication-ready-plots",
    "title": "03. Data Analysis with Jupyter and Python",
    "section": "Towards Publication-Ready Plots",
    "text": "Towards Publication-Ready Plots\nTry to achieve as much of the final figure requirements as possible via code\n\nall_metrics = iris_tidy.metric.unique()\n\nall_metrics\n\narray(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'],\n      dtype=object)\n\n\n\ny_titles = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\nletters = ['A', 'B', 'C', 'D']\n\n\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(2, 2, figsize=(10, 10))\n\nall_axes = ax.flatten()\n\nfor i, metric in enumerate(all_metrics):\n    \n    current_axes = all_axes[i]\n    \n    sns.swarmplot(data=iris, size = 3.5, \n                  x='species', y=metric, hue = 'species',\n                  ax=current_axes)\n\n    current_axes.set(ylabel=y_titles[i])\n\n    \n    current_axes.set_ylim(0, 10)\n    current_axes.get_ylim \n    current_axes.get_legend().remove()\n    current_axes.text(-1, 10.5, letters[i], fontsize = 25, fontweight = 'semibold')\n\nC:\\Users\\xusy\\.conda\\envs\\nbdevdabestdev\\lib\\site-packages\\seaborn\\categorical.py:1296: UserWarning: 20.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n  warnings.warn(msg, UserWarning)\n\n\n\n\n\n\nf.savefig(\"myplot.svg\")\nf.savefig(\"myplot.png\", dpi = 300)"
  },
  {
    "objectID": "dabest_introduction.html",
    "href": "dabest_introduction.html",
    "title": "04. DABEST Introduction",
    "section": "",
    "text": "DABEST is a package that performs estimation statistics available on Python and R. With Jupyter Notebook you can try DABEST-Python. Before you are able to import the DABEST package, you need to install it. You can do so by going to your Anaconda Navigator>Environments Tab>base(root)>open Terminal.\nAfter this you can run >pip install dabest\n\nimport pandas as pd\nimport dabest\n\n# don't worry about these lines.\nimport warnings\nimport matplotlib.cbook\nwarnings.filterwarnings(\"ignore\", category=matplotlib.cbook.mplDeprecation)\n\n\n# Read iris data from the sheet with pandas\niris = pd.read_csv('iris.csv')\n\n\niris.head()\n\n\n\n\n\n  \n    \n      \n      sepal_length\n      sepal_width\n      petal_length\n      petal_width\n      species\n    \n  \n  \n    \n      0\n      5.1\n      3.5\n      1.4\n      0.2\n      setosa\n    \n    \n      1\n      4.9\n      3.0\n      1.4\n      0.2\n      setosa\n    \n    \n      2\n      4.7\n      3.2\n      1.3\n      0.2\n      setosa\n    \n    \n      3\n      4.6\n      3.1\n      1.5\n      0.2\n      setosa\n    \n    \n      4\n      5.0\n      3.6\n      1.4\n      0.2\n      setosa\n    \n  \n\n\n\n\n\niris_analyze = dabest.load(data=iris, \n                           x=\"species\", y=\"sepal_length\",\n                           idx=(\"setosa\", \"virginica\")\n                          )\n\n\niris_analyze.mean_diff\n\nDABEST v0.3.9999\n================\n                \nGood evening!\nThe current time is Wed Feb  1 12:40:28 2023.\n\nThe unpaired mean difference between setosa and virginica is 1.58 [95%CI 1.38, 1.78].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis ofzero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\n\niris_analyze.mean_diff.plot();"
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "01. Introduction",
    "section": "",
    "text": "As research techniques and data collection have become almost completely digital and analysis methods grow more sophisticated, it is critical that scientists develop three skills: data visualization, statistics, and coding. Unfortunately, many undergraduate biology programs emphasize the memorization of numerous facts, while failing to offer courses in data graphics, estimation statistics, or scientific programming. In this session, we offer a basic orientation on these topics."
  },
  {
    "objectID": "introduction.html#before-class",
    "href": "introduction.html#before-class",
    "title": "01. Introduction",
    "section": "Before class",
    "text": "Before class\nIf any issues can‚Äôt be resolved with the below steps, we can work on it in the class together.\n\nYou‚Äôll need to get set up with a version-control system. Go to GitHub and get an account. Download and install GitHub Desktop.\nRetrieve the course materials from GitHub. Go to the course repository (‚Äúrepo‚Äù) at https://github.com/ACCLAB/moda. Click the green Code button and then select Open with GitHub Desktop. You will be prompted to select a directory for the local repository. If you are using a PC it can be something like this:  If you are using a mac, it can be something like ‚Äú//Users/YOURUSERNAME/Documents/GitHub/moda‚Äù.\nTo get set up with Python and Jupyter notebooks, install the Anaconda Distribution on your laptop.\nOpen Anaconda Navigator and launch JupyterLab by clicking on it.JupyterLab will open in a browser tab.\nIn the File Browser panel in JupyterLab, navigate to the folder where you cloned the course repo (refer to step 2). Double click on ‚Äònbs‚Äô. You should see a list of notebook files. Open ‚Äú02_Quick_tour_of_the_Notebook.ipynb‚Äù by double-clicking on the icon shown in the JupyterLab browser window.\nWork through the notebook. Familiarize yourself with basic Python, and with working in the JupyterLab environment.\nRead about pandas, matplotlib, and seaborn.\nRead our papers on estimation statistics here and here."
  },
  {
    "objectID": "introduction.html#in-class",
    "href": "introduction.html#in-class",
    "title": "01. Introduction",
    "section": "In class",
    "text": "In class\n\nAn overview of data analysis.\nA tour of the estimationstats web app.\nPresentation of a Jupyter notebook that introduces techniques in data analysis using Python.\nTry JupyterLite, an experimental web version of JupyterLab, with a class notebook here."
  },
  {
    "objectID": "introduction.html#further-practice-and-resources",
    "href": "introduction.html#further-practice-and-resources",
    "title": "01. Introduction",
    "section": "Further practice and resources",
    "text": "Further practice and resources\nTry using the estimationstats.com web app to analyze your own grouped data.\nOpen and have a look at the sample multivariate data. Go through the introductory notebook that demonstrates data analysis.\nWe recommend the following texts to strengthen your data-analysis and presentation skills. They can be dipped into over the coming months or years, and used as references. Being familiar with some or all of this material will help you write your first-author paper/s and doctoral thesis.\n\nKey resources\n\nEstimation: Our estimationstats.com site has introductory information on estimation and specific types of analyses and effect sizes.\nDatavis: Claus Wilke‚Äôs free online book is a great introduction to data visualization, and a style guide. It is written in R, which is the best language for statistics.\nCoding: There are many online resources to learn coding. Published in 2021, A Data-Centric Introduction to Computing uses a Python-like teaching language (Pyret) to introduce key concepts in computer science.\n\n\n\nAdditional resources\n\nSome are free, some you will need to buy or borrow from the library.\n\nEstimation: If you want to learn about estimation statistics in greater depth, there is Calin-Jageman and Cumming‚Äôs textbook that is well-written, funny, and clear. The authors also run a blog.\nEstimation: Christoph Bernard‚Äôs account of the pioneering experience of a major journal (eNeuro) recommending estimation as standard: the initial announcement, author feedback, and after one year.\nCoding: The paid coding tutorial Learn Python The Hard Way has a good reputation, but there are also many free options (see DCIC above) with great reviews.\nCoding: It will help to learn to use your computer‚Äôs Unix-style command-line shell. This interface will allow you to use package managers like conda and homebrew, version-control tools like git, and other important tools. There are many books about the shell, with only minor differences between MacOS, Windows, and Linux.\nDatavis: A brief guide to oral‚Äìvisual data presentations (talks).\nDatavis: A reader-funded textbook on typography, including for slides. Since so much communication relies on text, typography is an important part of the data interface.\nDatavis: For historical perspectives, Edward Tufte‚Äôs books are classic texts to develop your design skills, and there is Friendly and Wainer‚Äôs History of Data Visualization.\nAs you progress, you will want to develop your skills in areas like bioinformatics, image processing, and/or machine learning. The iris dataset is widely used for training in multivariate data analysis, with many online tutorials.\n\n\nThe social reasons to learn programming also apply to research programming.\n<iframe width=\"600\" height=\"400\"\nsrc=\"https://www.youtube.com/embed/kgicuytCkoY\">\n</iframe>\n\nThe social reasons to learn programming also apply to research programming."
  }
]